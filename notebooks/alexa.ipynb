{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk import word_tokenize\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/workspaces/codespaces-jupyter/data/Topical-Chat/conversations/train.json\") as f:\n",
    "    raw_json = f.read()\n",
    "json_data = json.loads(raw_json)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all phrases from dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "conversations_ids = list(json_data.keys())\n",
    "for i in range(len(conversations_ids)):\n",
    "    conversation = json_data[conversations_ids[i]][\"content\"]\n",
    "    for conv in conversation:\n",
    "        texts.append(conv[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Well they want a lot of Awards this year, and I think they're going to do even better next year\n",
      "### Full sequnce:  want year this\n",
      "### Root want \n",
      "### Well they want a lot of Awards this year, and I think they're going to do even better next year\n",
      "### Full sequnce:  want year\n",
      "### Root want \n",
      "### Well they want a lot of Awards this year, and I think they're going to do even better next year\n",
      "### Full sequnce:  want think going do year next\n",
      "### Root want \n",
      "### Well they want a lot of Awards this year, and I think they're going to do even better next year\n",
      "### Full sequnce:  want think going do year\n",
      "### Root want \n",
      "### Oh wow that's awesome! I've always wanted to go, but I will be going probably next year, we're thinking about going to the Philippines. And we may stop in Japan or China while we're over there. Have you ever been to Mackinac Island by the way?\n",
      "### Full sequnce:  wanted thinking going year next\n",
      "### Root wanted \n",
      "### Oh wow that's awesome! I've always wanted to go, but I will be going probably next year, we're thinking about going to the Philippines. And we may stop in Japan or China while we're over there. Have you ever been to Mackinac Island by the way?\n",
      "### Full sequnce:  wanted thinking going year\n",
      "### Root wanted \n",
      "### Hi how's it going! Do you plan on watching the Academy Awards this Sunday? They give a total of 24 awards in the film industry.\n",
      "### Full sequnce:  plan on watching Sunday this\n",
      "### Root plan \n",
      "### Hi how's it going! Do you plan on watching the Academy Awards this Sunday? They give a total of 24 awards in the film industry.\n",
      "### Full sequnce:  plan on watching Sunday\n",
      "### Root plan \n",
      "### That is touching!  Speaking of touching, just wanted you to know that UNICEF has a thing going where they will donate a day of clean water to a needy child for every minute a person does NOT use their cell phone. This is a great thing they are doing. It helps the children and encourages less exposure to cell radiation. Win win!\n",
      "### Full sequnce:  wanted know has thing going donate day a\n",
      "### Root wanted \n",
      "### That is touching!  Speaking of touching, just wanted you to know that UNICEF has a thing going where they will donate a day of clean water to a needy child for every minute a person does NOT use their cell phone. This is a great thing they are doing. It helps the children and encourages less exposure to cell radiation. Win win!\n",
      "### Full sequnce:  wanted know has thing going donate day\n",
      "### Root wanted \n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    if (text.find(\"going\") != -1):\n",
    "        doc = nlp(text)\n",
    "        for token in doc:\n",
    "            if (token.ent_type_ == \"DATE\"):\n",
    "                token_next = token\n",
    "                token_seq = [token]\n",
    "                while(token_next.dep_ != \"ROOT\"):\n",
    "                    token_next = token_next.head\n",
    "                    token_seq.append(token_next)\n",
    "                token_seq.reverse()\n",
    "                if (token_seq[0].lemma_ in [\"plan\", \"going\", \"want\"]):\n",
    "                    print(f\"### {text}\")\n",
    "                    print(\"### Full sequnce: \", \" \".join([i.text for i in token_seq]))\n",
    "                    print(f\"### Root {token_seq[0]} \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
